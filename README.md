# Neural Networks from Scratch: A Journey from Perceptrons to Transformers

This repository is designed to help you understand various neural network architectures, from the basics of perceptrons to advanced transformer models. The focus is on practical implementation using PyTorch, with real-world examples in data, text, audio, and images.

**Prerequisites**: To fully benefit from this repository, you should have a solid understanding of Linear Algebra, Statistics, and basic Python programming.

## Installation

To set up the environment, follow these steps:

```bash
git clone https://github.com/greg2705/NeuralNetworks.git
cd NeuralNetworks
poetry lock
poetry install
```

## Repository Structure 

1. **Introduction** : Neural Networks & Perceptron Theory, concrete example, python implemntation of a single layer perceptron.
2. **Standard Neural Networks** : MLP using Pytorch.
3. **Convolutional Neural Networks (CNNs)** : CNNs using Pytorch.
4. **Recurrent Neural Networks (RNNs)** : The Long Short Term Memory Network (LSTM) using Pytorch.
5. **Generative Adversarial Network (GAN)** : GAN using Pytorch.
6. **Transformer Neural Networks** : Implementing a french Language Model (Small One) using Pytorch.

